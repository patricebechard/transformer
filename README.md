# Transformer and Generative Pre-Training

This repo contains (will contain shortly) a PyTorch implementation of the Transformer architecture (Vaswani et. al. 2017) as well as experiments with generative pre-training (Radford et. al. 2018, Devlin et. al. 2018).

The repo also contains slides for a presentation given for the Scientific Discussions at Intact Data Lab.

